---
title: "Math 120 Week 13-14"
author: "Ali Miller"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    code_folding: show
    theme: yeti
    df_print: paged
  
  
---

```{r setup, include=FALSE}

#---------- RSTUDIO STARTER V 2.0  --------------#
#                    -Prepared with care by  AM ;D
                
                                                                          
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)      
library(tidyverse)                
library(ggthemes)                    

theme_set(theme_tufte() +                                     
  theme(text=element_text(family="sans")))  

studentSurvey <- read_csv("Student Data.csv")
deathPenaltyData <- read_csv("death penalty data.csv")
housingData <- read_csv("../Data/House-Sales.csv")
#------------------------------------------------#
```





# Monday Nov 9

## Inference for Quantitative Data (Ch 7)

So far, all of our inference has been about categorical data.  Ie, we've performing inference on **p**, the population proportion!

Now, let's do the same things for quantitative data.  Ie, we'll be performing inference on **mu**, the population mean.

Recall, there are two major types of statistical inference:

 - CIs are used to **estimate** population parameters (p, and mu)
 - Hyp tests are use to investigate a claim/answer a question about a population parameter (p, and mu).
 
 
The only reason this is possible is because of the CLT: as long our sample size is "large enough", then the sample statistics we collect follow a normal distribution.


For proportions (phat):  if np>10 and n(1-p)>10, then phat follows a normal dist with 

- mean = p
- stdev = sqrt(p*(1-p)/n)



For means (xbar):  if n > 30, then xbar follows a normal dist with

- mean = mu (population mean)
- stdev = sigma/sqrt(n)   (sigma is the population stdev).

The above gives us everything we need to do inference with means.

Ex)  Mean height for women in the US is 64" with std 2.4".  If we take sample of 40 women, what's the probability that their average height is greater than 64.3"?

Since n>30, we know xbar follows a normal dist.

Q:  Compute P( xbar >64.3 )

Find z-score:

    z = (obs - exp)/stdev
      = (64.3 - 64)/(2.4/sqrt(40))
      
      
```{r}
 (64.3 - 64)/(2.4/sqrt(40))
```

```{r}
1-0.7852
```

There's about a 21.48% chance that, in a sample of 40 women, their avg height is at least 64.3".

## Hyp Tests for mu

Suppose that, in a sample of 50 men at DU, their avg height is computed to be 69.7" and stdev = 3.2".  THIS IS **S**, NOT SIGMA!!

Does this provide statistically significant evidence the mean height of men at DU is higher than the national average of 69?


1) Hypotheses

H0: mu = 69
Ha: mu > 69

2)  Test statistic:

    z = (obs - exp)/stdev
      = (xbar - mu)/(sigma/sqrt(n))

Problem!  What's sigma?  Remember, the whole reason we're doing this hyp test is because we DON'T KNOW what the population parmeters are!  Definitely don't know mu, that's what we're here for. So, why would we know sigma?  WE DON'T!!

Oh no!  What to do??

Need to use the next best thing:  sample standard dev, s!

Ok, but there's another problem:

    (xbar - mu)/(s/sqrt(n))  DOESN'T follow a normal distribution!

The answer:  use a modified version of the normal distribution called the 

  **t distribution**!!
  
![](https://andyjconnelly.files.wordpress.com/2017/05/distributions1.png)  
  

Let's get to know "t" a little better.  Important properties:

 - looks just like the normal dist!  bell-shaped, and symmetric about 0.
 - importand difference:  the t dist has "thicker tails".  This has two consequences:
   - it makes our CIs wider, since we need to go further out to get the middle%
   - it makes p-vals bigger in Hyp Tests, since tail area is bigger!
  
These differences are a huge bummer!  CIs an Hyp Tests based on t are less good/successful.  However, we have be honest.  This is the price that we pay for not knowing the population standard deviation sigma!

Back to our test:

    t = (69.7-69)/(3.2/sqrt(50))
    
Here:

- xbar = 69.7 (observed mean)
- mu = 69 (expectation from the Null Hyp)
- s = 3.2 (std dev of our data)
- n = 50

```{r}
(69.7-69)/(3.2/sqrt(50))
```

WARNING:  the t-table is a arranged a little differently.  The specific shape of the t-dist depends on the sample. In order to use the table, need a sample size.  Here, we call this "degrees of freedom" or "df".

   df = n - 1 = 50-1
   
Our df = 49

3) P-val

From the t-table, our p-val (tail area) must be between .05 and .10.  

    .05 < p < .10
    
4)  Since p>.05, we FAIL to reject H0.  There's not strong evidence to support the claim that men at DU have mean height greater than 69".



### Summary of difference between proportions (categorical) and means (quant):

- for proportions, use the z table.  exp = p, stdev = sqrt(p(1-p)/n)

- for means, use the t table.  exp = mu, stdev = s/sqrt(n)



# Wed Nov 11

## Hyp tests for mu (ctd)

Recall, since we don't know the population stdev, sigma, we have to use the t dist.

Recall, the test stat for p (proportions):

z = (phat - p)/sqrt(p(1-p)/n)

Assume the value of p in H0, phat comes from data.

Now, for mu (means):

z = (xbar - mu)/(sigma/sqrt(n))

Since we don't know sigma, forced to use s (sample stdev) instead.  THAT'S why we need the t dist:

t = (xbar - mu)/(s/sqrt(n))

REMEMBER:  in any test or CI involving "means/averages", use the t dist!

**Ex** Average IQ in the US is 100.  A researcher wonders:  do musicians have higher average IQ than the general population?

Suppose, in a sample of 50 musicians, their average IQ was computed to be 105, stdev 12.2.  (xbar = 105, s = 12.2, n=50)

Conduct a hypothesis test to investigate the claim.


1) Hypotheses

H0: mu = 100
Ha: mu > 100  (right tail test!)

2) Test stat

     t = (obs - exp)/stdev
       = (105 - 100)/(12.2/sqrt(50))
       
```{r}
(105 - 100)/(12.2/sqrt(50))
```

So, t = 2.90.


3) p-val.  We have t=2.90 and df = n - 1 =  49.  

From table, p < .005 (since t value is larger than anything in the table).

This means that, if the mean IQ of musicians really is 100, then there's less than a 0.5% chance of observing a sample mean that's as large as the one we got.

4)  Conclusion

Since p<.05, we reject H0.  There's strong evidence that the mean IQ of musicians is greater than the pop mean of 100.

Yay!  Our claim was supported!

# Friday Nov 13

### Reminder:  Two-tail tests

The above example is a "one-tail" test, since we're checking ">".  But remember, if the Ha is "!=", then we need a "two tail area".



**Ex** Mean height for women in the US is 64.  Suppose a researcher wonders if mean height for women in Russia differs from women in the US.

To investigate, the reseracher collects data about 50 randomly selected women in Russia, and calculates their avg height to bo 64.3" with stdev 2.8".

H0: mu  = 64
Ha: mu != 64  (two-tail test!)

2) Test stat

```{r}
(64.3 - 64)/(2.8/sqrt(50))
```

t = .758, df = 50 - 1 = 49.

3) p-val.  From the table:  p-val > .2

If the mean height for women in Russia really is 64", then there's over 20% chance of obtaining a sample result that's as large as ours (64.3").  

4) Conclusion:  Since p>.05, we fail to reject H0.  We did not find strong evidence that the mean height of women in Russia differs from the mean in the US.


## Comparing Two Populations

(2 samp tests)

So far, we've developed methods for performing statistical inference on ONE population.  Ie, saying something smart about a population proportion or a population mean.

Oftentimes, we wish to compare two populations.  Is the mean of one bigger than the mean of the other?  Does one proportion differ from the other?

First, let's talk about two proportions: p1 and p2.

We always make inference about the DIFFERENCE between them:  p1 - p2.

Need the same pieces:

- estimator: phat1 - phat2 (the two sample proportions)
- mean/expected: p1 - p2   (the two pop proportions)
- stdev:  sqrt( p1(1-p1)/n1 + p2(1-p2)/n2 )

Confidence intervals for p1 - p2:

    phat1 - phat2 +/- zstar*sqrt( p1(1-p1)/n1 + p2(1-p2)/n2 )

        estimator +/  critval * stdev

**Ex**  In a sample of 100 DU students, 78 of them were from out-of-state.  In a sample of 150 Oberlin students, 139 of them were from out of state.

Construct a 95% CI to estimate the difference in proportion of out-of-state students between the two schools.

For zstar, need bounds of the middle 95%.  In table, look up area = .025, thus zstar = 1.96.

phat1 = 78/100,  n1 = 100
phat2 = 139/150, n2 = 150

```{r}

(78/100-139/150) - 1.96*sqrt(78/100*(1-78/100)/100 + 139/150*(1-139/150)/150)


```


```{r}
(78/100-139/150) + 1.96*sqrt(78/100*(1-78/100)/100 + 139/150*(1-139/150)/150)

```

We're 95% confident that the difference in proportion out-of-state students between DU and Oberlin is between -23.8% and -5.5%.

                    -23.8%  <  p1 - p2 < -5.5%

Think:  if a - b is a negative number, which is bigger?  b is bigger!

Here, seems like p2 is bigger, ie the proportion of out-of-state students at Oberlin is likely higher.  


## Hyp tests for two proportions  

In a sample of 100 DU students, 78 of them were from out-of-state.  In a sample of 150 Oberlin students, 139 of them were from out of state.

Does this data provide statistically significant evidence that the proportion of out-of-state students at DU **differs** from the proportion at Oberlin?

1) Hypotheses

H0:  p1 - p2  = 0  (ALWAYS THE H0!!!)
Ha:  p1 - p2 != 0  (two tail test)

2) Test stat

Same format:

    z = (obs - exp)/stdev

Wrinkle in the problem:  in the null hypothesis, we're assuming that the two proportions are the same!

Because of that, it makes sense to "pool" our sample data together.  We call this the "pooled" proportion:

phat_p = (x_1 + x_2)/(n_1 + n_2) = (all "successes")/(total sample size)

      (78+139)/(100 + 150)

```{r}
(78+139)/(100 + 150)
```

Here, phat_p = .868  

Let's use this in our test stat:

    (78/100 - 139/150 - 0 )/sqrt( .868*(1-.868)/100 + .868*(1-.868)/150  ) 



```{r}
(78/100 - 139/150 - 0 )/sqrt( .868*(1-.868)/100 + .868*(1-.868)/150  ) 
```

z = -3.36.

Look up in table, tail area = .0004.  SInce two-tail, our p-val = .0008.


4) Conclusion:  Since p<.05, we reject H0.  We found strong evidence that the proportion of DU students who are out-of-state differs from the proportion at Oberlin.



WHOOPS!  USED THE WRONG TABLE!  PROPORTION IS ALWAYS Z! 



# Monay Nov 16

## 2-samp tests for means


If two samples, we always do inference on the DIFFERENCE between them:  mu1 - mu2


estimator:  xbar1 - xbar2
expected:   mu1 - mu2
stdev:      

    sqrt(s1^2/n1 + s2^2/n2)  
  
where s1 and s2 are the sample stdevs for the two samples.

Since talking about means, we'll ALWAYS use the t-dist!

Q:  since there are two samples, what's the df? 

A1:  Use a long nasty math formula

A2:  Use the shortcut:  choose the smaller of the two!


CI:  

    estimator  +/- critval*stdev
    
    xbar1 - xbar2 +/- tstar*sqrt(s1^2/n1 + s2^2/n2)
    
**Ex**  A hungry math professor wondered:  is there a difference in delivery time between Donatos and Elms?

To investigate, she collected data about 42 Donatos deliveries (mean time 23 min, stdev 5 min) and 35 Elms deliveries (mean time of 28 minutes, stdev 6 min).

Construct a 95% CI to estimate the DIFFERENCE in mean delivery times.


Donatos: n1 = 42, xbar1 = 23, s1 = 5

Elms:    n2 = 35, xbar2 = 28, s2 = 6

Find tstar.  Middle 95% area.  Use df = 35-1 = 34.  From table, tstar = 2.03.

Low bound:

```{r}
23 - 28 - 2.03*sqrt(5^2/42+6^2/35)
```

```{r}
23 - 28 + 2.03*sqrt(5^2/42+6^2/35)

```

            -7.59 < mu1 - mu2 < -2.41
            
We're 95% confident that the true difference in mean delivery time between Dominos and Elms is between -7.59 min and -2.41 min.

Think:  mu2 is bigger than mu1!  Makes us think that Elms has greater delivery time!

### Hyp test for two means

**Ex**  A hungry math professor wondered:  is there a difference in delivery time between Donatos and Elms?

To investigate, she collected data about 42 Donatos deliveries (mean time 23 min, stdev 5 min) and 35 Elms deliveries (mean time of 28 minutes, stdev 6 min).

Perform an appropriate hyp test to determine if there's statistically significant evidence of a *difference* in mean delivery time.

Donatos: n1 = 42, xbar1 = 23, s1 = 5
Elms:    n2 = 35, xbar2 = 28, s2 = 6

1) Hypotheses

H0: mu1 - mu2  = 0  (ALWAYS the H0 for 2 means!!!)
Ha: mu1 - mu2 != 0  (two-tail test!)

2) Test stat

    t = (obs - exp)/stdev
    
      = (23-28 - 0)/sqrt(5^2/42 + 6^2/35)
      
```{r}
(23-28 - 0)/sqrt(5^2/42 + 6^2/35)
```
      
      
t = -3.92, df = 35-1 = 34.  


3) pval

Look for +3.92.  Find:  p-val < .01.


4) Since p<.05, we reject H0.  There's strong evidence of a difference in mean delivery times between Donatos and Elms.



### SUmmary of difference between 2-prop and 2-mean tests

For 2-prop, use z score:

    z = (phat-phat2 - 0)/sqrt(phat_p(1-phat_p)/n1 + phat_p(1-phat_p)/n2)

where phat_p is the combined "pooled" sample proportion. 

For 2-means, use t score:

    t = (xbar1-xbar2 -0)/sqrt(s1^2/n1 + s2^2/n2)
    
For df, use the smaller of the two

# Friday Nov 18

## Error Types for Hypothesis tests

Our tests always end in one of two options:

- Reject H0
- Fail to reject H0

BUT, in reality, either:

- H0 True
- H0 False

Somtimes, with "unusual" data ("unrepresentative"), the conclusion of our Hyp Test could be wrong!!

![](https://sketch.io/render/sk-d307d5811f1ee8a4d56163191c475849.jpeg)

**Examples**

1) An EPA enforcement officer suspects that the mean concentration of a toxic chemical in a local water water supply is greater than the federally mandated max of .8g/ml.  

To investigate, she takes 40 samples from local water sources and finds a mean concentration of the toxic chemical to be .85g/ml.

Q:  What would type I and type II errors really MEAN in this case?

H0:  mu = .8     (water is ok.)
Ha:  mu > .8     (water is dangerous!)

Type I error:  rejected H0, but actually H0 is true.  We think that the water is dangerous, but actually it's ok.

Type II error:  fail to reject H0, but actually H0 is false.  We think the water is ok, but actually the water is dangerous!!



2) Criminal Trial:

H0: innoncent
Ha: guilty

Type I error:  We think they're guilty, but actually they're innocent.
Type II error:  We think they're innocent, but actually they're guilty.


### Factors affecting type I and type II error

The probability of getting a type I error is ALPHA!!  The significance level of the test.  Usually, there's a 5% chance of a Type I error.

But, the choice of alpha is up to the investigator.

The chance of a Type II error is inversely proportionl to the chance of a type I error.  Gotta balance!


If Type I is worse, use smaller alpha.
If Type II is worse, use larger alpha!!!!












































    

    
    
    











