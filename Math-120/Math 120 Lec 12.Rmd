---
title: "Math 120 Lec 12"
author: "Your Name"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    code_folding: show
    theme: simplex
    df_print: paged
  
  
---

```{r setup, include=FALSE}

#---------- RSTUDIO STARTER V 2.0  --------------#
#                    -Prepared with care by  AM ;D
                
                                                                          
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)      
library(tidyverse)                
library(ggthemes)                    

theme_set(theme_tufte() +                                     
  theme(text=element_text(family="sans")))  

#------------------------------------------------#
```

## Sampling With Replacement

#### Ex: Bag of Marbles

A bag of 20 marbles has 12 blue, 8 red marbles.  If you draw three marbles in a row, what's the chance that all three are blue?


First marble:  12/20 chance of blue
2nd marble:  11/19
3rd marble: 10/18

All together:  (12/20)*(11/19)*(10/18) = whatev

It was important that we didn't replace the marbles.

Q:  How would it be different if we *did* replace the marbles?

A:  The probabilities don't change, these become independent events!

P(all thee blue) = (12/20)*(12/20)*(12/20)

The issue here is sampling with replacment.

Replacement means "independent", since each outcome doesn't affect the others.

Q:  How different are they?

```{r}

(12/20)*(11/19)*(10/18)

(12/20)*(12/20)*(12/20)

```

There's about a 3 percent difference.  Not huge, but substantial.

Q:  How would the math work if we had 20000 marbles?

```{r}
# compare replacement vs not replacement

#first, no replacement

(12/20000)*(11/19999)*(10/19998)

#with replacement

(12/20000)*(12/20000)*(12/20000)
```
No replacment:  P = .000000000165
Replacement:    P = .000000000216

Matt's observation:  as population size increases, the difference beteween replacement and not replacement gets very small. 

Ie, if we've got a big population, **we don't care** if we're replacing or not!  They're basicaly the same!

#### Moral of the story

We assume independence whenever our population is large relative to the sample size:  

A common rule of thumb, the sample should be no more than 5% of the population size.

Ex:  If our sample is size 5, and pop is size 100, we assume independence.

**NOTE**  Lab 3 #2!!!!!

## Discrete Random Variables

A discrete random variable assigns a **real number** to every outcome in a probability experiment.

In order to do math with this stuff, we need numerical represenations.


## Discrete Probability Distributions

A discrete distro is a discrete random variable, along with the probabilities for each.

Usually, we represent these as tables.

### Simple Example: Rolling a single dice

Scenario:  we roll a dice.  The discrete random variable (RV) X is the face that shows.

Outcomes for X:  1, 2, 3, 4, 5, 6

Here's how to do this in R

```{r}
X1 = c(1, 2, 3, 4, 5, 6)

P1 = c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)

```




## Expected Value of a discrete distro

An important quality of a distribution:  the "expected" value, i.e., the thing we expect in the long run.

It's a weighted average of all the outcomes of X, weighted by probability.

### Definition

Formula:  E(X) = sum(x*P(x))


### Example: single dice

This is super easy to find in R:

```{r}
X1
P1

#Find expected value:

sum(X1*P1)

```

Q:  When you roll a dice, how frequently do you get a 3.5?

**Arya's observation**:  isn't it like average?

**Prof Miller's reply**:  isn't average different every time?

Connected to Law of Large numbers:  as sample size increases, observed proporiton gets closer to the true probability.

Here, we're not talking individual outcomes, we're talking about **whole samples**!  Means!

If we take larger and larger samples of dice rolls, we expect our average to get closer and closer to 3.5.  

```{r}
#sample 10000 dice rolls

diceSample <- sample(1:6, 10000, replace = TRUE)


mean(diceSample)

```

Observation:  large sample size has average that's close to the expected value.  If n increases, it "generally" gets closer still.

#### 3.30a Expected Value

```{r}
X = c(0,5,10,20)
P = c(26/52, 13/52, 12/52, 1/52)

sum(X*P)

```


If we play the card game many times, our average winnings will be close to $3.94.   (And thus, it's probably foolish to pay $5 to play this game.) 



## Variance of a discrete distro


### Single dice example


## Data Example:  mpg