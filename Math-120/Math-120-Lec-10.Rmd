---
title: "Math 120 Week 10"
author: "Prof Miller"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    df_print: paged
    theme: cerulean
    toc: yes
    toc_depth: 3
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}

#---------- RSTUDIO STARTER V 2.0  --------------#
#                    -Prepared with care by  AM ;D
                
                                                                          
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)      
library(tidyverse)                
library(ggthemes)                    

theme_set(theme_tufte() +                                     
  theme(text=element_text(family="sans")))  

#------------------------------------------------#
```




# Week 10 - Vid 1

**Pre-reading Assignment: Texbook Section 5.2**

Now that we know about sampling distributions, we're ready to deploy the most useful statistial tools:

- Confidence Intervals, and 
- Hypothesis Tests

Both of these are example of **Statistical Inference**:  making mathematically-supported conclusions about a population based on sample statistics.

We'll talk about confidence intervals first.  












## Confidence Intervals - The Idea

Remember, a **statistic** is a numerical summary of a sample.  We've thought about many in this class so far, but the two we'll focus on now are:

- phat, the sample proportion (categorical data)
- xbar, the sample mean (quantitative data)

In this video, we'll focus on phat.  














As we've seen, statistics vary randomly just as samples vary randomly.  Imagine we're wondering about the proportion of DU students who are international students.

- Population:  DU students
- Variable: Whether or not the student is international
- Type:  categorical
- Statistic: phat, sample proportion

Different random samples will always give us different sample proportions.  Makes sense -- they contain different students!

But, what can we say about the **population**?  Remember, a **parameter** is a summary of a population.  Here, we're wondering about **p**, the population proportion of DU students who are international.

The big idea is this:  since we know what the distribution for phat is, we can use that to estimate what p must have been.

These are **BACKWARDS** problems -- we're looking for a range of reasonable values for p!

To put it another way, Confidence Intervals let us **estimate**  p based upon phat!

Let's look at the formula.

















## Confidence Intervals for population proportion, p

We learned previously that the z-score for proportions looks like this:

(+/-) z = (phat - p)/sqrt(p*(1-p)/n)

Remember from our practice in backward problems that we use both the + and - z-score to get the upper and lower bounds.  If you don't understand what I mean, PAUSE THE VIDEO AND REVIEW BACKWARDS PROBLEMS FOR PHAT!

With a little algebra, this formula can be re-arranged to solve for p, the population proportion.  It looks like this:

p = phat  +/-  z*sqrt( p(1-p)/n )

where:

- phat = sample proportion
- z = cutoffs for middle C%  (ie middle 95%, middle 99%, or anything else we want)
- n = sample size

There's one problem:  since we're trying to make an estimate for p, that means we don't have everything we need on the right side of the equation.  So, we do the next best thing and use phat, the sample proportion, instead.  As long as the CLT is satisfied (how big does n have to be?), then this is ok.













## Formula for CI for p

Suppose we find a sample proportion phat from a random sample of size n.  If n is large enough to satisfy the CLT ( np>10 and n(1-p)>10 ), we can estimate that:

  phat - z sqrt( phat(1-phat)/n )  <  p  <  phat + z sqrt( phat(1-phat)/n )  
  
In pretty typesetting:

$$ \hat{p}-z\cdot \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} < p < \hat{p}+z\cdot \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$

In other words, we conclude that the population proportion is betwen those two bounds.

This is almost identical to the backwards problems we did last week!

Picture:   

                  (---------------- phat ----------------)













## Example 1

Suppose we take a random sample of 100 DU students, and find that 55 of them are female.  

Based upon this, estimate the proportion of all DU students who are female with 95% confidence.

Note:  estimate == conf int

Q:  is n big enough for CLT?

np > 10, and n(1-p) > 10, i.e., need 10 in the category and 10 not in the category

Here:  yes!  55 women (bigger than 10), and  45 not women (bigger than 10).

phat = 55/100 = .55
n = 100

Need z:  what are the cutoffs for the middle 95% of normal dist?  Look at table:

If 95% in the middle, then 2.5% for each tail.  Look for .025.  Here:

"critical" z score = 1.96.  Note:  z score for CI is called "critical value"

z = 1.96

Formula:  phat +/- z*sqrt(phat(1-phat)/n)

First, lower bound:

```{r}
.55 - 1.96*sqrt(.55*(1-.55)/100)
```

Find upper bound:

```{r}
.55 + 1.96*sqrt(.55*(1-.55)/100)
```

We are 95% confident that the true proportion of DU students who are female is between 45.2% and 64.6%.












## Example 2

Suppose we take a random sample of 60 DU students, and find that 16 of them watched "Love Is Blind", the reality dating show on Netflix.  

Estimate the proportion of all DU students who watch Love Is Blind with 90% confidence. 

Info:

- n is big enough, since >10 successes and >10 failures
- phat = 16/60

Critical value, z:  need cutoffs for the middle 90% of normal dist.

If 90% in the middle, each tail has 5%.  Find .005 in the table: use z = 1.645  (split the difference). 

Formula:  phat +/- z*sqrt(blah blah)

Low bound:  

```{r}
16/60 - 1.645*sqrt(16/60*(1-16/60)/60)
```

Upper bound:

```{r}
16/60 + 1.645*sqrt(16/60*(1-16/60)/60)
```

Based upon this sample, we are 90% confident that the true proportion of DU students who watch Love is Blind is between 17.3% and 36.1%.  






# Vid 2

## Important parts of CIs

Note:  "CI" always means "Confidence Interval".

Confidence Intervals are our first tool for statistical inference:  we use them to estimate population paramaters (like mu and p) based on sample statistics (like xbar and phat).

















Last time, we learned the CI for p:

                phat +/- z*sqrt(phat(1-phat)/n)

We'll see many CIs in this class, and they all have the same form:

              (point estimate) +/- (critical value)*(standard error)
              
Let's think about each of these:

- The point estimate is a single number that approximates the population parameter.  For proportions, we use phat, the sample proportion.  **The point estimate is always the middle of the CI!**

- The critical value is the z score.  This determines how wide our confidence interval is going to be.  It's based upon the **confidence level**, C.  For example, if we want to be 95% confident, then we need the z score for the middle 95% of the normal curve.  
  - Since confidence values of 90%, 95%, and 99% are very common, you'll frequently see their corresponding critical values of z=1.645, z=1.96, and z=2.575.  You should know how to find these yourself!  Backwards z table!
  
- The standard error is the stanard deviation of the sampling distribution.  For phat, that's sqrt(phat(1-phat)/n).  We'll see other examples in the future!
  
  
  
  
  
  
  
  
  
  
  
## Margin of Error

MOE means exactly what you think:  how far "off" might our estimate be?

Mathematially, it's everything after the +/- in the confidence interval.  For phat, that's:

MOE = z*sqrt(phat(1-phat)/n)

Of course, we always hope that the MOE will be **small**, so that we have a precise estimate of the population parameter!

We have some control over this...











## Factors that affect the MOE

There are two major factors:

1) Sample size.  If sample size goes up, MOE goes down.  Look at the formula again:

MOE = z*sqrt(phat(1-phat)/n)

Since we're **dividing by n**, bigger n means smaller MOE!  Yay!  This is good!  

2)  Confidence level.  This one is kind of a bummer.  In order to be more confident, we need to include a wider range of values.  That means our critical values have to be bigger.  But, that means BIGGER MOE!  

In short:  being more confident means having a larger margin of error. Bummer!!!











## Planning for MOE

Since it's possible to control sample sizes, we can (hopefully) engineer our studies to provide a desired margin of error.  

Think like this:  If I want an estimate that's very accurate, how big would my sample size have to be?

This is a pretty easy question to answer:  just solve for n in the MOE formula!

Remember, MOE = z*sqrt(phat(1-phat)/n)

After a little algebra, we have

n = phat(1-phat)*(z/MOE)^2

If we have a prior estimate for phat, use that.  If not, use phat = .5 as a "worst case scenario".  It turns out that .5 will give you the largest possible MOE.

Then, n = .5*(1-.5)(z/MOE)^2

CALCULUS NOTE:  Did you take calculus?  Remember "optimization" problems?  Well, phat = .5 is the solution to the question "what value produces the maximum margin of error?"  Conclusion:  calculus is why we have nice things.  ;D


















## Example 1

In a previous study of student tv viewing habits, we approximated the proportion of DU students who watch Love Is Blind to be 26.7% with a margin of error of 9.4%.  <small>(You might wanna review that example to make sure you believe me.  I'm eating Fruit Loops right now, maybe I messed up?  ;D)</small>.

Suppose that we wish to conduct a new study, where we hope to estimate the proportion of DU students who watch Love Is Blind with margin of error no greater than 5%.  Use the same 90% confidence.  How large must our sample be?

n = phat(1-phat)(z/MOE)^2

Have a prior estimate:  26.7%  (16/60).  

Since 90% confident, z = 1.645

MOE desired:  5%

Let's find n:

```{r}
.267*(1-.267)*(1.645/.05)^2
```

Need n = 212.  In order to obtain a margin of error no greater than 5%, we'd need to sample 212 students.













## Example 2

Suppose we wish to estimate the proportion of DU students who are vegetatian.  There is no prior information available.  We'd like our estimate to be accurate to within 1%, with confidence level of 95%  How many students must we sample?

We hope to construct a 95% CI with MOE no greater than 1%.  How many students?  What's n?

Since no prior estimate, use phat = .5.  Worst case scenario.

Formula:  n = phat(1-phat)(z/MOE)^2

phat = .5  (no prior)
z = 1.96 (confidence 95%)
MOE = .01

```{r}
.5*(1-.5)*(1.96/.01)^2
```

Uh oh!  Moral of the story:  too greedy!  Can't have such a small MOE!  Try again!






# Week 10 - Vid 3


## CIs for mu

In the first two videos this week, we investigated the meaning and application of confidence intervals for categorical data.

Today, we'll continus that discussion in a new context: quantitative data.

Remember,

- We summarize **categorical** data with the sample proportion **phat**.  We use it as an approximation to **p**, the population proportion (the thing we're hoping to learn about).

- We summarize **quantitative** data with with the sample mean **xbar**.  We use it as an approximation to **mu**, the population mean (the thing we hope to learn about).

We know from the CLT that the distributions for both xbar and phat is normal for large sample sizes.  So, we can use xbar to estimate mu just like we did with phat and p.















## CI for mu - The Formula

Remember, all CIs have the following structure:

       (point estimate) +/- (critical value)*(standard error)
       
That's still true for means!  But, in this context:

- The point estimate is **xbar**, the sample mean.
- The critical value is the same as before:  the bounds for the middle 90/95/99/whatever%
- The standard error is sigma/sqrt(n)

If that formula for the standard error looks unfamiliar, you should stop and review Week 8's notes.  This is what you used in the denoninator of your z-scores there!

So, putting it all together, we can make an approximation for mu, the population mean, with this formula:

    xbar +/- z*sigma/sqrt(n)
    
**There's a problem here, however!!  This is not the final formula!**  













## The problem with means

So, why can't we just use the above formula and call it a day?

Here's the rub:  if we don't know the population mean (mu), then why in the world would we know the population standard deviation (sigma)???

We totes wouldn't!  That's the point:  we're doing this because we DON'T know the population parameters!!  In real life, Prof Miller can't just magic up the true values.

So, what's the solution?

The solutions:  we'll use the **sample standard deviation** instead.  

I.e., use s instead of sigma.  After all, s is easy to compute.  For example from the iris dataset:

```{r}
sd(iris$Sepal.Length)
```
However, s is bound to have error.  So, **there's a price we pay**....














## The Price We Pay:  The "t" Distribution

Using "s" from the sample, instead of "sigma" from the population is, in short, **not as good**.

It turns out, this little "cheat" actually **changes the shape of the sampling distribution**.

In short:  we can't use the Z table for these problems.  Oh, no!  

The good news is: it's still possible to know the shape of the resulting distribution based on s instead of sigma.  

In fact, we call it the "t" distribution.  Check it out in the back of your book!

In practice, when performing statistical inference for means (including CIs for mu), **we use the t distribution to find critical values instead of the z distribution**.

It's not a big deal:  it's just a different table (or, in software, a different computer function)
















##  Using the t distribution

Before we can do neat tricks like make Confidence Intervals, we need to learn how to read the t table.  It's a little diffferent from the z table!

To the human eye, the t dist and the z dist look very, very similar:

- both are bell-shaped
- both are symmetric
- both centered at zero

However, the t dist has two important differences:

- it's tails are thicker; they have more area.
- the shape of t depends on the sample size (called degrees of freedom; df = n-1).   

Since the t dist depends on sample size (whereas the normal dist doesn't!), the t table has to be re-arranged to accomodate this.

I think it's easiest to learn by example, so let's practice some easy ones together.










## Example 1

If our sample size is n=34, what are the cutoffs for the middle 95% of the t distribution?

Here, df = n - 1 = 34 -1 = 33.  Df = 33.

Tail area:  one-tail area = 2.5%,  two-tail = 5%

Cutoffs:  -2.03, +2.03.  Ie, the middle 95% of the t dist (df = 33) is between t=-2.03 and t=+2.03.









## Example 2

If our sample size is n=22, what are the cutoffs for the middle 98% of the t distribution?

Df = 22 -1 = 21.

One-tail area:  1%,   Two-tail area: 2%


Cutoffs:  t  =  +/- 2.52









## Back to CIs - The REAL CI for mu

Now that we know how to use the t distribution, we can finally put all the pieces together, we can finally use it to construct CIs for mu:

    xbar +/- t*s/sqrt(n)
    
Phew!  That's it!  Once you get the hang of it, they're easy to make.











## Requirements for CIs

In order for any of this to work, we need to know that xbar is following a normal distribution.  Remember, there are two ways:

- If the data (X) follows a normal dist, then the sample mean (xbar) will also
- If the sample size is "large enough" (n>=30), then xbar is normal no matter what

**Either one of these is enough**, but we **need at least one**!  In other words:  if your sample size is small, and your data doesn't follow a normal distribution, then **you can't construct CIs for mu!!**  The CI is -not- guaranteed to contain the true population parameter, mu!

I'll be sure to talk through this in each example.  (And, if I ever forget, then you should earn your student stars by asking me in office hours!)

Let's put it all to work!






## Example 3


Suppose we wish to estimate the mean resting heartrate of DU students.  We take a sample of 55 DU students, and find a mean resting heart rate of 64.3 bpm, std dev 5.8 bpm.

Constuct a 99% CI to estimate the true population mean bpm for students.


xbar = 64.3
s = 5.8
n = 55   ->  df = 54

Critical value:  one-tail area = .5%.  t = 2.68.  

Plug and chug:

xbar +/- t*s/sqrt(n)

Lower bound:
```{r}
64.3 - 2.68*5.8/sqrt(55)
```

Upper bound:

```{r}
64.3 + 2.68*5.8/sqrt(55)
```

We are 99% confident that the true mean heart rate of DU students is between 62.204 bmp and 66.396.



















