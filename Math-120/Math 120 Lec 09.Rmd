---
title: "Math 120 Lec 09"
author: "Your Name"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    code_folding: show
    theme: simplex
    df_print: paged
  
  
---

```{r setup, include=FALSE}

#---------- RSTUDIO STARTER V 2.0  --------------#
#                    -Prepared with care by  AM ;D
                
                                                                          
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)      
library(tidyverse)                
library(ggthemes)                    

theme_set(theme_tufte() +                                     
  theme(text=element_text(family="sans")))  

#------------------------------------------------#
```

## Reading Discussion: What is Randomness?



## Final Considerations about Linear Models (for now)

### Use numerical variables

Warning:  Liner regression doesn't make sense for categorical variables.

Extra warning:  R will still try to do it anyway.  That doesn't mean it's correct.

```{r}

mpg %>% head

```

Here, it doesn't make sense to use manufacturer or model (or any of the other categorical variables!).

```{r}

stupidModel <- lm(cty ~ manufacturer, data=mpg)


summary(stupidModel)
```

Even though we get a summary, this still doesn't make much sense!

Warning for lab:  definitely don't use a categorical variable for you final model!



### Correlation â‰  causation!

Just because two things are correlated, that *doesn't* mean that one causes the other.

It's possible that there's a causal relationship, but that's very hard to show.  Need many experiments (not observational studies)!!!




### Spurrious Correlations


Notice how silly those correlations are, but also notice that r is very strong for all!

Just because there's a strong r, that doesn't mean that one causes the other.  Super, super, super important!

### Randomness



## In-class Demo: Gambling!!!


Interesting observation:  for the original dice rolls, they're all over the place.  1s, 2s, 3, ..., 6s.. they're all equally likely and impossible to predict.

However, the -averages- over many rolls are **very** predictable.

This illustrates the key idea of probabilty: individuals are impossible to predict, but **groups** are very predictable.  The bigger the group, the better our prediction.


### Key Ideas:

(note: all in text in chapter 3)

- A random event or random experiment is any scenario where the outcome is unknowable.  I.e, dice roll.

- The probability that an event E occurs isthe proption of times we'd observe E, if we repeated the experiment an infinite number of times.

Example:  Let's say E = we roll a 4.

Intuitive (and correct) answer:  1/6.  If we could roll our dice infinity times, we'd see a "4" on 1 out of every six rolls.

Question:  how can we roll the dice an infinite number of times??

Answer:  you can't!  Have to settle for the largest n we can afford.  

This isn't terrible news, because of the **law of large numbers**!

### Law of large numbers

As the number of repetitions (n) of an experiment increases, our observed proportion will become closer and closer to the true probability.

What a relief!  As long as n is big, our observed probability is close to the true prob.  **And**, we can say how close (i.e., margin of error).

Dice example:  true average is 3.5, and you all got close to it (between 3 and 4).  More dice rolls, you get closer still!

Probability is the math tool that lets us make conclusions about our data!!  This works because **randomness is highly ordered**.
