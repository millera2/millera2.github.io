---
title: "Math 120 Lab 5: Solutions Outline"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    code_folding: show
    theme: yeti
    df_print: paged
  
---

```{r setup, include=FALSE}
###########################################################################
################# DON'T DELETE THIS PART!!!!!##############################
###########################################################################
                                                                          #
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)      #
                                                                          #
library(tidyverse)           #The tidyverse has all of our data tools     #
library(ggthemes)            #ggthemes makes our graphs look nicer        #
library(pander)                                                                          # 
theme_set(                                #this sets the theme for all    #
  theme_tufte() +                         #plots that we make             #
  theme(text=element_text(family="sans"))                                 #
  )                                                                       #
                                                                          #
                                                                          #
                                                                          #
### Below is where you read and store your data.                          #
                                                                          #
options(digits=3)  
set.seed(1)
politicalData <- read_csv("../Data/political-data.csv")#
                                                                          #
                                                                          #
############# ^ ################################# ^ #######################
############# | ## DON'T DELETE THIS PART!!!!!### | #######################
############# | ################################# | #######################
```



## Intro


Lab 5 is an investigation into political party affiliation in the Show of Hands survey app.  For my analysis, I picked "income level" as the metric along which I'd study the subgroups.  One might wonder:  is there a relationship between income level and party identification?  Of course there are many dimensions that relationship might take; this lab will only investigate the proportions we observe in sample results.  Looking to the future, we'll add to our toolbox for answering, "is there a relationship between these variables?"  

The major goals in this lab are to see confidence intervals in action, to compare the results from multiple samples, and to analyze the relationship between confidence level and margin of error for CIs.  It's a sneaky way to do an analysis:  if we consider our data as the entire "population", we can make interesting observations about how the samples behave and get a feel for how successful the method is in general.

## Setup

First, we filter the data into subgroups (statisticians actually call this "subgroup analysis") and take samples from each.  If this were an actual publication, I would omit the details presented here, since they're not interesting for the readers and not needed to analyze the results.  Note that in R, you can omit code chunks by adding `include = FALSE` to the opening `{r}` chunk tag.

First, I need to see what subgroups I have to work with.  (Here I'm showing you, my students, how I think about problems like this.  I need to see: what's in the dataset?  What are the names of the variables?  What are the *levels* of the category I'm interested in?  I gave you guys a lot of pointers in class, but I hope you can learn to be more autonomous in your investigations.)

```{r}

colnames(politicalData) %>% pander
unique(politicalData$Income) %>% pander

```

(Notice that I've used the `pander` function to make the output prettier.  That's a neat trick, for those of you who want to use R in the future.)


Now that I know what the levels are, I can filter.  **Notice that the names I choose are easily legible for both you and me**; nobody will have trouble understanding what they mean in future commands.  **Consistent naming choices also make copy/pasting easier**, which is a huge time-saver!  Also notice how I use whitespace to make the code easier to read.


**Not shown here**:  I also used the `nrow` command on each to make sure that the filter really worked.  There's no point in going further if we don't have good data!  Every time I perform an operation on my data, I perform "sanity checks" to see if it worked as intended/expected.  That output isn't interesting for readers though, so don't include it in a report.

```{r}
over150     <- politicalData %>% filter(Income == "over $150,000")
btwn75to100 <- politicalData %>% filter(Income == "$75,000 - $100,000")
btwn100to150<- politicalData %>% filter(Income == "$100,001 - $150,000")
btwn50to75  <- politicalData %>% filter(Income == "$50,000 - $74,999")
btwn25to50  <- politicalData %>% filter(Income == "$25,001 - $50,000")
under25     <- politicalData %>% filter(Income == "under $25,000")

```

Now that we've got the subsets, let's find the proportion per party in each one.  This will be the "true proportion" that we'll used to judge the effectiveness of our confidence intervals by later. A proportion is simply a ratio: the number ($x$) in our category of interest divided by the total ($n$).  In math:
$$\hat{p}=\frac{x}{n}$$
In the code below, notice how my naming convention makes it perfectly clear what all of these things are; you don't have to be a statistician or a computer programmer to understand what they mean.  Note that I am not specifically endorsing any particular party by using "Democrat".  I'm a queer vegetarian Marxist utopian liberal arts math professor, but all humans are warmly welcome in my classroom.  ;D

```{r}
over150prop      <- sum(over150$Party     =="Democrat")/nrow(over150)
btwn75to100prop  <- sum(btwn75to100$Party =="Democrat")/nrow(btwn75to100)
btwn100to150prop <- sum(btwn100to150$Party=="Democrat")/nrow(btwn100to150)
btwn50to75prop   <- sum(btwn50to75$Party  =="Democrat")/nrow(btwn50to75)
btwn25to50prop   <- sum(btwn25to50$Party  =="Democrat")/nrow(btwn25to50)
under25prop      <- sum(under25$Party     =="Democrat")/nrow(under25)

```


Now that we know what's going on with the "populations" (the scare quotes here indicate that these aren't *reall* populations), let's take our samples and find sample proportions for each.  I'll stick with Democrats to be consistent.  Again, notice that my spacing and naming really help readability!

```{r}


over150sample      <- sample(over150$Party,      50)
btwn75to10sample   <- sample(btwn75to100$Party,  50)
btwn100to150sample <- sample(btwn100to150$Party, 50)
btwn50to75sample   <- sample(btwn50to75$Party,   50)
btwn25to50sample   <- sample(btwn25to50$Party,   50)
under25sample      <- sample(under25$Party,      50)

over150phat      <- sum(over150sample     =="Democrat")/50
btwn75to100phat  <- sum(btwn75to10sample  =="Democrat")/50
btwn100to150phat <- sum(btwn100to150sample=="Democrat")/50
btwn50to75phat   <- sum(btwn50to75sample  =="Democrat")/50
btwn25to50phat   <- sum(btwn25to50sample  =="Democrat")/50
under25phat      <- sum(under25sample     =="Democrat")/50




```

## Constructing the CIs

We know, from the Central Limit Theorem, that sample statistics like $bar{x}$ and $\hat{p}$ follow a normal distribution.  That fact is surprising and complex, but the idea of a confidence interval is simple:  find the range of the middle $C\%$ of the sampling distribution for our particular sample result. The formula only involves three terms:  $\hat{p}$,  $z^*$, and $n$.  
$$\hat{p} \pm z^* \sqrt{\frac{p(1-p)}{n}}$$
We've got our sample info $\hat{p}$ and $n$; now we need critical values $z^*$ to find the range of the middle 50% and 95% of our sampling distributions.  We find these cutoffs with `qnorm`, a function that uses the normal distribution "backwards" to give us z-scores that correspond to a particular area under the curve.  

A 95% interval spans the middle 95% of the sampling distribution, leaving 2.5% area in the tails.  Ergo we use `qnorm(.025`), and the result is the familiar $z^* = 1.96$.  The 50% intervals cover the middle 50%, thus they have 25% of the area in each tail.  We use `qnorm(.25)`, and the result is a critical value of $z^* = .674$ for the 50% intervals.

```{r include=FALSE}
z_50 <- .674
z_95 <- 1.96
```

Fortunately with our setup, the intervals are easy to compute.  The code is virtually identical for all of them, and my naming scheme made it easy to copy/paste throughout.  Later on, it'll be easy for me to remember the names and quickly *clack* them out into my summary table.

```{r}

# First, the 50% intervals

under25_lower_50      <- under25phat -      z_50*sqrt(under25phat*(1-under25phat)/50)
under25_upper_50      <- under25phat +      z_50*sqrt(under25phat*(1-under25phat)/50)

btwn25to50_lower_50   <- btwn25to50phat -   z_50*sqrt(btwn25to50phat*(1-btwn25to50phat)/50)
btwn25to50_upper_50   <- btwn25to50phat +   z_50*sqrt(btwn25to50phat*(1-btwn25to50phat)/50)

btwn50to75_lower_50   <- btwn50to75phat -   z_50*sqrt(btwn50to75phat*(1-btwn50to75phat)/50)
btwn50to75_upper_50   <- btwn50to75phat +   z_50*sqrt(btwn50to75phat*(1-btwn50to75phat)/50)

btwn75to100_lower_50  <- btwn75to100phat -  z_50*sqrt(btwn75to100phat*(1-btwn75to100phat)/50)
btwn75to100_upper_50  <- btwn75to100phat +  z_50*sqrt(btwn75to100phat*(1-btwn75to100phat)/50)

btwn100to150_lower_50 <- btwn100to150phat - z_50*sqrt(btwn100to150phat*(1-btwn100to150phat)/50)
btwn100to150_upper_50 <- btwn100to150phat + z_50*sqrt(btwn100to150phat*(1-btwn100to150phat)/50)

over150_lower_50      <- over150phat -      z_50*sqrt(over150phat*(1-over150phat)/50)
over150_upper_50      <- over150phat +      z_50*sqrt(over150phat*(1-over150phat)/50)

## Now, all the 95% intervals


under25_lower_95      <- under25phat -      z_95*sqrt(under25phat*(1-under25phat)/50)
under25_upper_95      <- under25phat +      z_95*sqrt(under25phat*(1-under25phat)/50)

btwn25to50_lower_95   <- btwn25to50phat -   z_95*sqrt(btwn25to50phat*(1-btwn25to50phat)/50)
btwn25to50_upper_95   <- btwn25to50phat +   z_95*sqrt(btwn25to50phat*(1-btwn25to50phat)/50)

btwn50to75_lower_95   <- btwn50to75phat -   z_95*sqrt(btwn50to75phat*(1-btwn50to75phat)/50)
btwn50to75_upper_95   <- btwn50to75phat +   z_95*sqrt(btwn50to75phat*(1-btwn50to75phat)/50)

btwn75to100_lower_95  <- btwn75to100phat -  z_95*sqrt(btwn75to100phat*(1-btwn75to100phat)/50)
btwn75to100_upper_95  <- btwn75to100phat +  z_95*sqrt(btwn75to100phat*(1-btwn75to100phat)/50)

btwn100to150_lower_95 <- btwn100to150phat - z_95*sqrt(btwn100to150phat*(1-btwn100to150phat)/50)
btwn100to150_upper_95 <- btwn100to150phat + z_95*sqrt(btwn100to150phat*(1-btwn100to150phat)/50)

over150_lower_95      <- over150phat -      z_95*sqrt(over150phat*(1-over150phat)/50)
over150_upper_95      <- over150phat +      z_95*sqrt(over150phat*(1-over150phat)/50)



```

The results are summarized in the table below:

| Category | sample $\hat{p}$ |   True p           |          50% CI                                   | 50% Success? |                 95% CI                |    95% Success? |
| ---      |  ---- |    ---            |          -----                                    |  ----        |                -----                     |  ---         |
|  <25k    | `r under25phat`  |  `r under25prop`     | (`r under25_lower_50`, `r under25_upper_50`) |     No           | (`r under25_lower_95`, `r under25_upper_95`) |       Yes |
| 25k<50k  | `r btwn25to50phat`  | `r btwn25to50prop`  | (`r btwn25to50_lower_50`, `r btwn25to50_upper_50`) | No         | (`r btwn25to50_lower_95`, `r btwn25to50_upper_95`) | Yes |
| 50k<75k  | `r btwn50to75phat`| `r btwn50to75prop`  | (`r btwn50to75_lower_50`, `r btwn50to75_upper_50`) | Yes        | (`r btwn50to75_lower_95`, `r btwn50to75_upper_95`) | Yes |
| 75k<100k | `r btwn75to100phat` | `r btwn75to100prop` | (`r btwn75to100_lower_50`, `r btwn75to100_upper_50`) | No       | (`r btwn75to100_lower_95`, `r btwn75to100_upper_95`) |Yes |
| 100k<150k| `r btwn100to150phat`  | `r btwn100to150prop`| (`r btwn100to150_lower_50`, `r btwn100to150_upper_50`) | Yes    | (`r btwn100to150_lower_95`, `r btwn100to150_upper_95`)|Yes |
| 150k<    | `r over150phat` | `r over150prop`     | (`r over150_lower_50`, `r over150_upper_50`) | No               | (`r over150_lower_95`, `r over150_upper_95`) |       Yes |

## Observations and Conclusion

Each of the 14 intervals above estimates the true population proportion of Democrats for their respective income categories.  Each of them is a statement about a *population*. For example, we're 50% confident that the proportion of Democrats in the income category *less than 25k* is between 43.2% and 52.7%.  Note that this specific example isn't a "successful" internal, since the true proportion of Dems was 52.9%.  Close, but no cigar!

We can make some interesting observations about the meaning of "success rate" here based on these results.  (Btw, as you can see in the code, I set my random number generator seed to "1" with `set.seed(1)`.  We'd see different results if we set the seed elsewhere; such is the nature of random samples!) For the 50% CIs, we see that 2 out of the 7 intervals were "correct" (although it's worth noting that some of these "failures" are quite borderline and very nearly capture the population parameter.)  For the 95% intervals, all 7 were successful.  This demonstrates two important properties of confidence intervals:

- The "confidence level" is the "success rate"; it determines how frequently this method is "correct".  It's **not** the probability that the true proportion lies within the particular interval we constructed.  Such a "probability" doesn't make sense:  either the confidence interval successfully captured the parameter, or it didn't!  Confidence only makes sense in the context of repeated trials.
- The confidence level isn't a prescription:  of course it's not the case that exactly half of our 50% CIs were successful.  Still, the general trend is expected:  Higher confidence leads to a higher success rate unequivocally.

Without exception, the margin of error is greater for the 95% intervals, i.e., they're "wider".  This makes sense:  in order to feel more confident that we're capturing the true proportion, we need to cast a wider net!

Another important observation is that the success of our CIs is strongly influenced by the particular sample proportion we find.  Even though each sample was of the same size $n=50$, some values for $\hat{p}$ are quite close to the true $p$, while others are quite a bit different.  Let this be a lesson:  your sample could be "good" (a close approximation to the population) or not, but *you have know way of knowing!*  We're "cheating" here by sampling from a known population, but generally we have know way of knowing whether or not our methods are successful.  Keep this in mind always when interpreting statistical results.

## Grading

I'm giving myself an A+ on these solutions.  I think I really killed it here.  It's exhausting being such a great professor!  ;D