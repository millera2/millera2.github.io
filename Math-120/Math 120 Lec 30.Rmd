---
title: "Math 120 Lec 28"
author: "Ali Miller"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    code_folding: show
    theme: simplex
    df_print: paged
  
  
---

```{r setup, include=FALSE}

#---------- RSTUDIO STARTER V 2.0  --------------#
#                    -Prepared with care by  AM ;D
                
                                                                          
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)      
library(tidyverse)                
library(ggthemes)                    

theme_set(theme_tufte() +                                     
  theme(text=element_text(family="sans")))  

#------------------------------------------------#
```



## Last Topic:  t Tests


Recall CLT:  As sample size increases,  our common sample statistics (like xbar and phat) follow normal dists.

Past 3 weeks:  all about phat and p (proportion) for categorical data.


Now: same thing, but with numerical/quantitave data.  In particular:  means!!!!

CLT works for xbar just like it does for phat:  if n is large, then xbar follows a normal dist with 

center = mu  (true pop mean)

std error = sigma/sqrt(n)

All together, we can make CIs and hyp tests.

## CIs for mu

Same format as always:  (Point est) +/- (crit val)*SE

Here:  xbar +/- (crit val)*sigma/sqrt(n)

## Hyp test

Same format as always:  z = (obs - exp)/(SE)

Here:  z = (xbar - mu)/(sigma/sqrt(n))

## One problem:  what's sigma????????!!?!?!

Recall, statistical inference is the process of making conclusions about our populations based upon our sample results.

In other words, we don't know what's going on with the population!!!!  We're trying to figure that out!!!

So, if we don't know mu, how on earth do we know sigma???

Solution:  use s instead, since of course we do have the sample std dev.


## One more problem: not quite normal

When we swap out sigma for s, the result isn't quite normal!!!  Instead, it folllows a very similar distribution:  the t distribution.

The idea is:  wihthout sigma, we have less info about the population.  We have to "pay" for it.  That price is the t distributuion.

T dist looks just like normal, but shorter with fatter tails.

This has two important effects:

- Wider CIS (bummer!)  I.e:  bigger Margin of Error (bummer!)
- p-vals are bigger with the t (bummer!)

Bummer!  But, it's how we "pay" for not knowing sigma.  

## Degrees of freedom

t dists depend on sample size.  Bigger n means closer to z (normal), which makes sense since larger n means more info about the population.

For n>100, virtuatlly no difference between t and z.

## Example:  CI for mean height

Suppose Prof Miller measure the height of all 23 of her stats students, and found a mean height of 66" with std dev 4.1".  Based on this sample result, estimate the true mean height of students at DU with 95% confidence.

Format:

xbar +/- (crit val)*s/sqrt(n)

xbar = 66
s = 4.1
n = 23

So what's crit val?

Recall for z, how did we find 1.96?

```{r}
qnorm(.025)
```

Here, same thing, but use qt instead of qnorm

```{r}
qt(.025, 23-1)  #note:  23-1 is the df (degrees of freedom)
```

Notice how T gives wider intervals:  2.074 instead of 1.96

```{r}
66 - 2.074*4.1/sqrt(23)
66 + 2.074*4.1/sqrt(23)

```

Based upon this sample, we're 95% confident that the true mean height of DU students is between 64.2 in and 67.8 in tall.  

Charlotte's Q:  always use df = n-1 for t dist stuff.

## Example

Suppose a sample of 31 giraffes is taken, and their avg height is computed to be 17.7 ft tall with std dev 2.9 ft.  Based upon this sample, estimate the mean height of all giraffes with 90% confidence.

crit val:

```{r}
qt(.05 , 30)    #  df = n-1
```

- xbar = 17.7
- s = 2.9
- tstar = 1.700
- n = 31

```{r}
17.7 - 1.700*2.9/sqrt(31)
17.7 + 1.700*2.9/sqrt(31)

```

We are 90% confident that the true mean height of all giraffes is between 16.8 adn 18.6 ft tall.  

## Hyp test

Suppose a sample of 31 giraffes is taken, and their avg height is computed to be 17.7 ft tall with std dev 2.9 ft.  Based upon this sample, estimate the mean height of all giraffes with 90% confidence.

A zoologist suspects that the true mean height of giraffes is less than 18' tall.  Does this sample provide strong evidence for this claim.  Conduct a hyp test.

H0:  mu = 18
Ha:  mu < 18

Test stat:

t = (xbar - mu)/(s/sqrt(n))

```{r}
(17.7 - 18)/(2.9/sqrt(31))
```

P-vals:  use pt instead of pnorm

```{r}
pt(-0.576, 31-1)
```


## Warm up example

In a sample of 55 setosa iris plants, the mean sepal width was computed to be 4.3cm with std dev 1.2cm.

Construct a 99% CI for the mean sepal length of all setosa irises.

Crit val:  qt

```{r}
qt(.005, 54)
```

Use tstar = 2.67

Formula:  xbar +/- tstar*s/sqrt(n)

```{r}
4.3 - 2.67*1.2/sqrt(55)
4.3 + 2.67*1.2/sqrt(55)

```
We're 99% confident that the true mean sepal length for all setosa irises is between 3.87cm and 4.73cm.

Based upon the above sample data, is there evidence to support the claim that the mean sepal length is less than 5cm?  Perform a hyp test.

H0:  mu=5
Ha:  mu<5

test stat:

```{r}
(4.3-5)/(1.2/sqrt(55))
```

p-val:

```{r}
pt(-4.326, 54)
```

Since p<.05, we reject H0.  There's strong evidence that the mean is less than 5cm.

## Example: ci for mu with iris dataset

```{r}
iris %>% head
```

Using the iris dataset, estimate the true mean petal length of iris flowers with 95% confidence.

What info do we need?

- mean  petal length
- stdev petal length
- n
- tstar

```{r}
# mean:

mean(iris$Petal.Length)
```

```{r}
#sd

sd(iris$Petal.Length)

```

```{r}
#nrow

nrow(iris)
```

```{r}
#tstar

qt(.025, 149)

```

Use tstar = 1.976

CI:

```{r}
3.758 - 1.976*1.765/sqrt(150)
3.758 + 1.976*1.765/sqrt(150)

```

We can be 95% confident that the true mean petal length of irises is between 3.47cm and 4.04cm.   

## Built-in functions

Since t intervals and tests are so common, there's a built-in method for doing it in R.  Magic!  It's called t.test.  

```{r}
t.test(iris$Petal.Length)
```


## Comparing two means:  mu1 - mu2

What if we have two groups that we want to compare means?  Everything is the same, but now we need expected value and std error fot mu1-mu2  (instead of just a single mu).

## Example

In Spring 2018, Prof Miller taught two sections of Math 120.  On exam 1, the first class had a mean score of 78 with std dev 6 while the second class had a mean score of 82 with std dev 5.  The first class had 24 students, and the second had 27 students.

Is there statistically significant evidence of a difference in mean exam score between the classes?

H0:  mu1 - mu2 = 0  (mu1 = mu2)
Ha:  mu1 - mu2 != 0  (note:  two tail!)

Test stat:

```{r}
#  xbar1 = 78, s1 = 6, n1 = 24
#  xbar2 = 82, s2 = 5, n2 = 27

(78-82)/sqrt(6^2/24+5^2/27)

```

p-val:  use pt as always.  For df by hand: just use the smaller of the two.  here:  df = 23

```{r}
pt(-2.568,23)*2
```

