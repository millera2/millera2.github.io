---
title: "DA 101 Lec 11"
author: "Your Name"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    code_folding: show
    theme: simplex
    df_print: paged
  
---

```{r setup, include=FALSE}

#---------- RSTUDIO STARTER V 2.0  --------------#
#                    -Prepared with care by  AM ;D
                
                                                                          
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)      
library(tidyverse)                
library(ggthemes)                    

theme_set(theme_tufte() +                                     
  theme(text=element_text(family="sans")))  

#------------------------------------------------#
```



## Confidence Intervals

CIs are methods of statistical inference, just hyp test.

Wait, what's inference?  It's making an educated guess, i.e., basing our prediction on evidence and reason.  

Statistical inference is the process of making conclusions about our populations, based on the sample data we take (and using probability).

There are two main types:  hyp tests **ask a question** about a population.  Is the mean bigger?  Is there a difference?  Etc...  We've seen these.

CIs are the other type of inference:  we use them for making an **estimate**.  Generally, "estimate" and "make a confidence interval" are synonymous.


### The idea

According to CLT, sample stats (like the mean) always follow normal distributions (for large samples).  In hyp tests, we center our bell curve on the null hypothesis (out assumption).

CIs are the other way around:  we center our bell curve around our ** sample result**.

In short, CIs give us a reasonable range of values for the population based on our sample data and probability.

NOTE:  CIs and Hyp Tests always give the same conclusion!!  I.e., a 95% CI is equivalent to a hyp test with alpha = .05.  More on this later.


### Examples: `mpg`, `iris`

First, let's do a confidence interval for one mean.  Our goal:  estimate the mean Sepal Length of the iris flowers.

```{r}
iris %>% head

qplot(iris$Sepal.Length)
```

In R, CIs are made automatically by 't.test()' command.

```{r}
t.test(iris$Sepal.Length)
```

(Note:  Ha:  mu !=0.  Since there's only one variable, R assumes 0 by default.)

The important part:  The CI.  Here, (5.7097, 5.9769).    What does this mean?  This:

We are 95% confident that the true population mean Sepal Length for the iris flowers is between 5.7097 and 5.9769.

The upshot:  we now have an estimate for the whole population!

Explicitly, the sample mean is:

```{r}
mean(iris$Sepal.Length)
```

The CI we found is centered around this point estimate.

Jon's question:  Let's compare species (2-samp CI)

```{r}
iris %>% filter(Species == "virginica") -> virginicaData
iris %>% filter(Species == "setosa") -> setosaData
```

Let's do t.test/CI in sepal length for these two groups:

```{r}
t.test(setosaData$Sepal.Length, virginicaData$Sepal.Length)
```

We're 95% confident that the difference in mean sepal length between the species is between -1.786 and -1.377.  Based on this interval, it is very unlikely that the difference is zero.  In other words, we conclude that there is strong evidence of a difference.  Note:  agrees with the p-val!!

Further:  since the difference must be negative, we suspect that the second one must be larger (i.e virginicas have longer sepal length).


### Connection to Hyp Tests
    
Hyp tests and CIs always give the same result.  Here's how it works:

If the H0 value is contained in the CI, then we fail reject H0.  It seems reasonable!

In the sepal length example, the null hyp:  mu1-mu2=0.  The CI was (-1.79, -1.38).  Since zero is not contained in the CI, we reject H0.  There's strong evidence of a difference.  The end.

## Error Types

Our tools (CIs and hyp tests) are based on data and math, but that doesn't mean that we always get the correct result.  Maybe, due to random chance or a bad sample or some other issue, the conclusion of the test could be wrong.

It's very, very important for us to consider what that might mean.  There are two possibilities:

Type I error (a false positive).  "Positive result" means we reject H0, because that supports our claim!  Type I error is when we reject H0, but in fact the null hyp was true!  We were wrong!

(Note:  in real life, it's almost impossible to know the truth).

Type II error (a false negative):  we fail to reject H0, but we should have becasue H0 is false.




### Hypothetical Examples (Worksheet)

1) EPA enforcement: we wonder if concentrations of Toxin A are above the safe level of 0.8 g/ml.  

$$H_0:\mu = .8$$ 

$$H_a: \mu > .8$$

Type 1:  We think the water is dangerous, but in fact it's not.

Type 2:  We think the water's fine, but actually it's dangerous.

Here, type 2 sounds much worse!  People would drink dangerous water!  I would feel bad about that, because I have human feelings.  

In type 1, we merely waste money cleaning up water that's already clean.  If you value money more than human life (some humans do), then you'd think a type 1 is worse.
        
### alpha
        
### beta
    
### Power of a hyp test
        







## Examples: 




